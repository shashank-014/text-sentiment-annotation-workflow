# Text Sentiment Annotation Workflow

## Project Overview

This project simulates a real-world text annotation workflow used in AI/ML pipelines.

The objective was to:

- Design structured annotation guidelines
- Manually label raw text data
- Measure inter-annotator agreement
- Analyze class distribution
- Train a simple machine learning model

## Annotation Process

1. Created annotation guidelines for consistency.
2. Manually labeled 50 text samples.
3. Simulated a second annotator to measure reliability.
4. Calculated Cohen's Kappa Score.
5. Evaluated model performance using Logistic Regression.

## Tools Used

- Python
- Pandas
- Scikit-learn
- Jupyter Notebook

## Key Insight

Clear annotation guidelines improve consistency, and high-quality labeled data directly impacts machine learning model performance.
